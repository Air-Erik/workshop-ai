# Спорные тейки и уточнения

Здесь фиксируем утверждения, которые требуют аккуратной формулировки
или уточнения под конкретную модель/инструмент.

---

## 1. "Модель — это T9 на стероидах"
**Статус:** в целом верно как упрощение, но не полное описание.

**Почему спорно:** современные модели используют сложные механизмы
внутреннего представления и не "угадвают" слово буквально, но на выходе
все равно выбирают следующий токен по вероятности.

**Обывательское объяснение (бытовая логика):**
- Модель не "думает", а продолжает текст так, чтобы он выглядел
  максимально правдоподобно.
- Она училась на огромном числе примеров и запомнила, какие фразы
  обычно идут после других.
- Поэтому выглядит "умной": не из-за понимания, а из-за статистики
  и паттернов, которые совпадают с нашей логикой и языком.

**Как говорить корректно:**
- "Это статистический генератор следующего токена по контексту."
- "Метафора с T9 полезна для понимания ограничений, но это упрощение."

---

## 2. "Модель видит диалог как книжный диалог"
**Статус:** в целом верно, если речь о текстовой последовательности.

**Уточнение:** система/роль/инструкции — это тоже часть текста.
Модель не "понимает" роли, она видит их как токены в последовательности.

**Как говорить корректно:**
- "Для модели это просто длинная строка токенов с пометками ролей."

---

## 3. "Весь диалог всегда отправляется из-за недетерминированности"
**Статус:** частично спорно.

**Уточнение:** контекст отправляется в первую очередь для согласованности
ответов и следования предыдущей истории, а не только из-за
недетерминированности. Реализация может включать кэш, усечение, резюмирование.

**Как говорить корректно:**
- "Контекст нужен, чтобы модель сохраняла согласованность."
- "Иногда часть истории резюмируется или кэшируется."

**Важное следствие (про стоимость):**
- Да, чем длиннее диалог, тем дороже каждое следующее сообщение, потому что
  в контекст снова попадает вся (или почти вся) история.
- Стоимость растет из-за увеличения входных токенов, даже если ответ короткий.
- Исключения: когда провайдер/инструмент применяет кэш или резюмирование.

---

## 4. "Модели по-разному обновляют файлы (полный файл vs патч)"
**Статус:** требует уточнения под Cursor/модель.

**Уточнение:** в Cursor обновление файлов может происходить через
дифф/патчи или через полный вывод файла — зависит от режима и модели,
но итоговая стоимость может зависеть и от текста, и от количества файлов.

**Как говорить корректно:**
- "Есть режимы/модели, где правки эффективнее как патчи."
- "Стоит проверять, как именно модель возвращает изменения."

**Замечание:**
- Если модель возвращает патчи (как git), это часто дешевле, чем пересылка
  целых файлов, но итог зависит от размера правки и политики провайдера.

---

## 5. "Ультра быстрые модели — тупые"
**Статус:** верно как эвристика, но есть исключения.

**Уточнение:** быстрые модели часто хуже на сложных задачах, но
могут быть достаточны для черновиков, поиска, простых правок.

**Как говорить корректно:**
- "Быстрые модели — для простого, умные — для сложного."

---

## 6. "Токен токену рознь (вход/выход/кэш)"
**Статус:** верно.

**Уточнение:** цены и категории токенов зависят от провайдера.
Важно различать вход и выход, а также кэшированные токены.

**Как говорить корректно:**
- "Следите за ценой входа/выхода и используйте кэш, где это возможно."
